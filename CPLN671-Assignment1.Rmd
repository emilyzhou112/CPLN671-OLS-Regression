---
title: "Using OLS Regression to Predict Median House Values in Philadelphia"
author: "Emily, Ziyi, Emma"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: simplex
    toc: yes
    toc_float: yes
    code_folding: hide
    code_download: yes
    
bibliography: references.bib

editor_options:
  markdown:
    wrap: sentence
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```


```{r libraries, message=FALSE, warning=FALSE, include=FALSE}

options(scipen = 999)

# all the library loaded
library(tidyverse)
library(here)
library(kableExtra)
library(ggplot2)
library(ggcorrplot)
library(sf)
library(patchwork)
library(MASS)
library(caret)

```


```{r read data, message=FALSE, warning=FALSE, include=FALSE}

# read in data
data <- read_csv(here("RegressionData.csv"))

```


# Introduction -- Ziyi

Housing values in Philadelphia have seen a consistent increase in recent years, making it an important area of concern and research for urban planners, policymakers, and residents. This upward trend has raised issues around housing affordability, particularly for low- and middle-income households. Many neighborhoods have experienced gentrification, leading to the displacement of long-term residents and changing the socio-economic landscape of the city. Examining housing values is critical for understanding these shifts and addressing concerns related to affordability, neighborhood stability, and equitable development across Philadelphia.

To better understand the potential factors influencing housing values in Philadelphia, we identified several key variables, including educational attainment, vacancy rates, the proportion of detached single-family homes, and poverty levels. These factors are closely linked to housing market trends and provide insights into the socio-economic conditions that may affect property values across the city.

The educational attainment of a population is closely linked to economic outcomes, including housing values. Studies suggest that areas with higher levels of education tend to have more robust local economies, higher incomes, and increased demand for housing, which pushes up home values @Scott2012. High vacancy rates are typically associated with declining neighborhoods and lower median house values. Vacant properties can be signs of economic distress, contributing to neighborhood decline through reduced upkeep, higher crime rates, and a negative perception of the area @mallach2018empty.In Philadelphia, the issue of vacancy has been particularly problematic in certain neighborhoods, where a large number of abandoned properties has led to significant reductions in housing values.@kromer2002vacant

The proportion of single-family homes in an area can also influence housing values, depending on the local market. Single-family homes are generally more desirable in many U.S. housing markets, as they offer more space, privacy, and perceived stability compared to multi-family units @glaeser2018economic. Research also consistently demonstrates a strong correlation between poverty levels and housing values. Areas with higher poverty rates often experience reduced demand for housing, as well as diminished investment in local infrastructure and services, which in turn can lead to lower property values @Galster2008. 

# Methods


## Data Cleaning - Emma
*Simply state that the original dataset had 1816 observations (i.e., block groups) and was cleaned in order to achieve a dataset with 1720 observations (that is, basically include the information about data cleaning that is on the very the first page of this assignment).

*Note that the original Philadelphia block group dataset has 1816 observations. We clean the data by removing the following block groups: 

- Block groups where population < 40
- Block groups where there are no housing units
- Block groups where the median house value is lower than $10,000
- One North Philadelphia block group which had a very high median house value (over 800,000) and a very low median household income (less than 8,000)

The original dataset used in this study consisted of 1,816 census block groups from the Philadelphia 2000 Census. In order to ensure that the dataset was suitable for regression analysis and to remove any extreme outliers or erroneous data, several data cleaning procedures were performed. First, every block group in the dataset with a population of less than 40 was removed. These block groups represent sparsely populated or unusually housed areas that may introduce noise into the analysis. In addition, block groups without any dwelling units were also excluded due to their lack of significance in a study centred on housing attributes. 

Additionally, block groups with a median housing value of less than $10,000 were not included. These block groups do not accurately reflect the reality of the typical housing market, and the unusually low home values in these block groups may bias the results of the study. Finally, a unique combination of values - median property values over $800,000 and typical household incomes less than $8,000 - led to the exclusion of one block group in North Philadelphia. Since this was a clear outlier, this block group was excluded to avoid biasing the results. After using these cleaning procedures, the final dataset includes 1,720 observations, each corresponding to a different Philadelphia block group. The cleaned dataset can now be used in more accurate and reliable regression analyses to test for associations between neighbourhoods.

## Exploratory Data Analysis - Emma
*State that you will examine the summary statistics and distributions of variables.
Also state that as part of your exploratory data analysis, you will examine the correlations between the predictors.  
*Explain what a correlation is, and provide the formula for the sample correlation coefficient r. Also mention the possible range of r values, and what correlation of 0 means.

In the first stage of exploratory data analysis, summary statistics and distribution of important variables will be examined. The median home value (MEDHVAL) is the dependent variable. The independent variables are the proportion of the population with a bachelor's degree or higher (PCBACHMORE), the number of households in poverty (NBELPOV100), the proportion of vacant homes (PCTVACANT), and the proportion of single family homes (PCTSINGLES). In addition, means and standard deviations were calculated for each variable. These summary statistics provide a better picture of the variability and central tendency of the data and provide a basis for more in-depth investigation. It may be necessary to address any strange patterns or outliers found by looking at these data before conducting regression analyses.

This study will investigate the correlations between the predictor variables in addition to descriptive statistics. Regression analysis can be complicated by multicollinearity, which can be identified by correlation, a measure of the linear relationship between two variables. The following formula is used to get the sample correlation coefficient, or r:

r=

In this formula, ð‘‹ð‘– and ð‘Œð‘– represent individual data points, and ð‘‹Ë‰ and ð‘ŒË‰ are the means of the variables ð‘‹ and ð‘Œ, respectively. The correlation coefficient r can range from -1 to +1. A value of +1 indicates a perfect positive linear relationship, where increases in one variable correspond with increases in the other, while a value of -1 indicates a perfect negative linear relationship. A value of 0 suggests no linear relationship between the variables, meaning changes in one do not predict changes in the other.

Understanding the correlations between the predictors is critical to identify whether any variables are highly correlated, which would suggest multicollinearity. Multicollinearity can distort the regression results by inflating the standard errors of the coefficients, leading to less reliable interpretations. Therefore, evaluating the correlations before proceeding to the regression analysis ensures the robustness of the model.

## Multiple Regression Analysis - Emily

Describe the method of regression in several sentences. What is it used for, what does it do?

State the equation for y for this problem. The equation should be in the form: by=Î²_0+Î²_1 x_1+â‹¯+Î²_k x_k+Îµ. 
However, in your report, instead of y and x1â€¦xk, fill in the actual variable names (as in the regression example given above). Be sure to mention what Î²iâ€™s and Îµ are as well. If the variables are log transformed, be sure to indicate that in the formulas.

State and explain regression assumptions (e.g., linearity; independence of observations; normality of residuals; homoscedasticity; no multicollinearity).

Mention the parameters that need to be estimated in multiple regression (Ïƒ2, Î²0 ,â€¦, Î²k). State what Ïƒ2 is (you should have already talked about Î²i in (ii) above). 

Talk about the way of estimating the parameters. (Hint: present the equation on the slide â€˜Î² Coefficient Estimation â€“ Least Squaresâ€™ for multiple regression and briefly discuss what the equation does).

Talk about the coefficient of multiple determination R2, and the adjusted R2. Present and explain the relevant formulas and all the terms that are used in the formulas.

State the hypotheses you test. Specifically, talk about the F-ratio and the H0 and Ha associated with it, as well as the hypotheses you test about each of the individual Î²iâ€™s (again, state H0 and Ha).

## Additional Analyses - Emily

Talk about stepwise regression â€“ discuss what it does and its limitations

Talk about k-fold cross-validation (mentioning that k = 5) â€“ discuss what it is used for, describe how it is operationalized and mention that the RMSE is used to compare models (explain what the RMSE is and how it is calculated, presenting and describing any relevant formulas).

## Software and Pacakges - Emily

State that youâ€™re using R for your data analysis.

# Results

## Exploratory Results - Ziyi

```{r mean and sd, message=FALSE, warning=FALSE}

# examine the mean and standard deviation of dependent and independent variables. 
dist_results <- data.frame(Variable = character(), Mean = numeric(), SD = numeric(), stringsAsFactors = FALSE)
variables <- c("MEDHVAL", "PCTBACHMOR", "NBELPOV100", "PCTVACANT", "PCTSINGLES")
relabelled_variables <- c(
  "Median House Value",                                    # MEDHVAL
  "% of Individuals with Bachelorâ€™s Degrees or Higher",    # PCTBACHMOR
  "# Households Living in Poverty",                        # NBELPOV100
  "% of Vacant Houses",                                    # PCTVACANT
  "% of Single House Units"                                # PCTSINGLES
)

for (i in seq_along(variables)) {
  
  mean_val <- round(mean(data[[variables[i]]], na.rm = TRUE), 3) 
  sd_val <- round(sd(data[[variables[i]]], na.rm = TRUE), 3) 
  
  # Store the relabeled variable names
  dist_results <- rbind(dist_results, data.frame(Variable = relabelled_variables[i], Mean = mean_val, SD = sd_val))
}


dist_results <- rbind(
  data.frame(Variable = "Dependent Variable", Mean = "", SD = ""),
  data.frame(Variable = "Median House Value", Mean = dist_results$Mean[1], SD = dist_results$SD[1]),
  data.frame(Variable = "Predictors", Mean = "", SD = ""),
  dist_results[-1, ] # Remove the first row because it has already been used above
)

dist_results %>%  
  kable(row.names = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% 
  row_spec(0, bold = TRUE) %>%  # Bold the header row
  row_spec(1, bold = TRUE) %>%  # Bold the 'Dependent Variable' row
  row_spec(3, bold = TRUE)


```

We began by summarizing the statistical data for median house values and various socio-economic predictors. The median house value has an average of \$66,287.73, with a standard deviation of \$60,006.08. This is significantly lower than both the county and state averages and shows considerable variation in house values. For educational attainment, 16.08% of individuals hold a bachelorâ€™s degree or higher, much lower than the state average of 35.3%. The standard deviation of 17.77% suggests notable variability in this measure. The average number of households living in poverty is 189.77, with a wide range reflected by a standard deviation of 164.32. Vacant houses make up an average of 11.29%, slightly higher than the state average of 9.4%, with a standard deviation of 9.63%. Finally, single house units account for an average of 9.23%, with a standard deviation of 13.25%. 


```{r histograms, fig.height=7, fig.width=9, message=FALSE, warning=FALSE}

# histogram

data %>%
  pivot_longer(cols = c("MEDHVAL", "PCTBACHMOR", "NBELPOV100", "PCTVACANT", "PCTSINGLES"),
               names_to = "Variable",
               values_to = "Value") %>% 
  ggplot(aes(x = Value)) +
  geom_histogram(aes(y = ..count..), fill = "#283d3b", alpha = 0.7) +  
  facet_wrap(~Variable, scales = "free", ncol = 3, labeller = as_labeller(c(
    "MEDHVAL" = "Median House Value",
    "PCTBACHMOR" = "% with Bachelorâ€™s Degrees or Higher",
    "NBELPOV100" = "# Households Living in Poverty",
    "PCTVACANT" = "% of Vacant Houses",
    "PCTSINGLES" = "% of Single House Units"
  ))) +  
  labs(x = "Value", y = "Count", title = "Histograms of Dependent and Predictor Variables") +
  theme_light() +   
  theme(plot.subtitle = element_text(size = 9,face = "italic"),
        plot.title = element_text(size = 12, face = "bold"), 
        axis.text.x=element_text(size=6),
        axis.text.y=element_text(size=6), 
        axis.title=element_text(size=8))




```

According to the histograms above, the original distributions were not normal. To address this, we applied a logarithmic transformation to the variables. 

```{r log variables, message=FALSE, warning=FALSE}

# log the variables

reg_data <- data %>%
  mutate(
    LNMEDHVAL = if (min(MEDHVAL) == 0) log(1 + MEDHVAL) else log(MEDHVAL),
    LNPCTBACHMOR = if (min(PCTBACHMOR) == 0) log(1 + PCTBACHMOR) else log(PCTBACHMOR),
    LNNBELPOV100 = if (min(NBELPOV100) == 0) log(1 + NBELPOV100) else log(NBELPOV100),
    LNPCTVACANT = if (min(PCTVACANT) == 0) log(1 + PCTVACANT) else log(PCTVACANT),
    LNPCTSINGLES = if (min(PCTSINGLES) == 0) log(1 + PCTSINGLES) else log(PCTSINGLES)
  )

```


```{r logged histograms, fig.height=7, fig.width=9, message=FALSE, warning=FALSE}

# histograms of the logged variables
reg_data %>%
  pivot_longer(cols = c("LNMEDHVAL", "LNPCTBACHMOR", "LNNBELPOV100", "LNPCTVACANT", "LNPCTSINGLES"),
               names_to = "Variable",
               values_to = "Value") %>% 
  ggplot(aes(x = Value)) +
  geom_histogram(aes(y = ..count..), fill = "#283d3b", alpha = 0.7) +  
  facet_wrap(~Variable, scales = "free", ncol = 3, labeller = as_labeller(c(
    "LNMEDHVAL" = "Median House Value",
    "LNPCTBACHMOR" = "% with Bachelorâ€™s Degrees or Higher",
    "LNNBELPOV100" = "# Households Living in Poverty",
    "LNPCTVACANT" = "% of Vacant Houses",
    "LNPCTSINGLES" = "% of Single House Units"
  ))) +  
  labs(x = "Value", y = "Count", title = "Histograms with Logged Transform Variables") +
  theme_light() +   
  theme(plot.subtitle = element_text(size = 9,face = "italic"),
        plot.title = element_text(size = 12, face = "bold"), 
        axis.text.x=element_text(size=6),
        axis.text.y=element_text(size=6), 
        axis.title=element_text(size=8))

```

This transformation has helped normalize some of the distributions, particularly for variables like median house value, number of households in poverty, and percentage of vacant houses. These variables now display more symmetric, bell-shaped distributions. However, for variables like the percentage of individuals with a bachelorâ€™s degree and percentage of single house units, the transformation was less effective, and they still deviate from a normal distribution. 

Moving forward, we will use the log-transformed results for our analysis. The remaining regression assumptions will be examined in detail in a separate section titled Regression Assumption Checks.


```{r corr plot, message=FALSE, warning=FALSE}

custom_labels <- c(
  "% of Individuals with Bachelorâ€™s Degrees or Higher" = "PCTBACHMOR",
  "% of Vacant Houses" = "PCTVACANT",
  "% of Single House Units" = "PCTSINGLES",
  "# Households Living in Poverty" = "LNNBELPOV100"
)

cor_matrix <- cor(reg_data %>% dplyr::select(PCTBACHMOR, PCTVACANT, PCTSINGLES, LNNBELPOV100))
rownames(cor_matrix) <- names(custom_labels)
colnames(cor_matrix) <- names(custom_labels)

ggcorrplot(cor_matrix, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           colors = c("#283d3b", "white", "#c44536")) +
  labs(title = "Correlation Matrix for all Predictor Variables") +
  theme(plot.subtitle = element_text(size = 9, face = "italic"),
        plot.title = element_text(size = 12, face = "bold"), 
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7), 
        axis.title = element_text(size = 8))
```

The choropleth maps of the dependent variable and the predictor variables reveal several notable patterns. The map displaying the percentage of individuals with a bachelor's degree or higher shows similarities to the map depicting the percentage of single-family housing units, both highlighting higher concentrations in the northwest, with additional clusters in Center City and the far northeast. In contrast, the maps illustrating households living in poverty and vacant housing share similar patterns, showing higher concentrations in the north, west, and parts of the south of the city. This suggests an inverse relationship between poverty and vacant housing with educational attainment and single-family homeownership, which is consistent with the correlation matrix.

Although some pairs of independent variables share general spatial patterns, they do not appear to be strongly correlated, and no severe multicollinearity is assumed. The correlation matrix validates this assumption, as no predictor pairs show very high correlations. 

Moreover, the dependent variable, median housing value, appears to follow a pattern similar to educational attainment and single-family homeownership, while demonstrating an opposite trend to poverty and vacant housing. Based on these visualizations, we can expect educational attainment, specifically the percentage of individuals with a bachelor's degree or higher, to have the strongest association with the dependent variable, as these maps exhibit the most similar patterns.

# Present the choropleth maps of the dependent variable and the predictors. Refer to the maps in the text, and talk about the following: Which maps look similar? Which maps look different? That is, which predictors do you expect to be strongly associated with the dependent variable based on the visualization? Also, given your examination of the maps, are there any predictors that you think will be strongly inter-correlated? That is, do you expect severe multicollinearity to be an issue here? Discuss this in a paragraph.

# Does the correlation matrix support your conclusions based on your visual comparison of predictor maps? 

```{r choropleth, message=FALSE, warning=FALSE}

# choropleth maps of predictor and dependent variables
philly <- st_read(here("shapefile", "RegressionData.shp"))
ggplot(philly) +
  geom_sf(aes(fill = LNMEDHVAL), color = "transparent") +
  scale_fill_gradientn(colors = c("#FAF9F6", "#c44536"), 
                       name = "LNMEDHVAL", 
                       na.value = "transparent") +  # Handle NAs
  theme(legend.text = element_text(size = 9),
        legend.title = element_text(size = 10),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.subtitle = element_text(size = 9, face = "italic"),
        plot.title = element_text(size = 12, face = "bold"),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "grey", fill = NA, size = 0.8)) +
  labs(title = "Log Transformed Median House Value")

```

```{r more choropleth, fig.height=11, fig.width=14, message=FALSE, warning=FALSE}

map_pctvacant <- ggplot(philly) +
  geom_sf(aes(fill = PCTVACANT), color = "transparent") +
  scale_fill_gradientn(colors = c("#FAF9F6", "#c44536"), 
                       name = "PCTVACANT", 
                       na.value = "transparent") +  # Handle NAs
  theme(legend.text = element_text(size = 9),
        legend.title = element_text(size = 10),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.subtitle = element_text(size = 9, face = "italic"),
        plot.title = element_text(size = 12, face = "bold"),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "grey", fill = NA, size = 0.8)) +
  labs(title = "% of Vacant Houses")

map_pctsingles <- ggplot(philly) +
  geom_sf(aes(fill = PCTSINGLES), color = "transparent") +
  scale_fill_gradientn(colors = c("#FAF9F6", "#c44536"), 
                       name = "PCTSINGLES", 
                       na.value = "transparent") +  # Handle NAs
  theme(legend.text = element_text(size = 9),
        legend.title = element_text(size = 10),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.subtitle = element_text(size = 9, face = "italic"),
        plot.title = element_text(size = 12, face = "bold"),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "grey", fill = NA, size = 0.8)) +
  labs(title = "% of Single House Units")

map_pcbachmore <- ggplot(philly) +
  geom_sf(aes(fill = PCTBACHMOR), color = "transparent") +
  scale_fill_gradientn(colors = c("#FAF9F6", "#c44536"), 
                       name = "PCTBACHMOR", 
                       na.value = "transparent") +  # Handle NAs
  theme(legend.text = element_text(size = 9),
        legend.title = element_text(size = 10),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.subtitle = element_text(size = 9, face = "italic"),
        plot.title = element_text(size = 12, face = "bold"),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "grey", fill = NA, size = 0.8)) +
  labs(title = "% Bachelor's Degree or Higher")


map_lnbelpov100 <- ggplot(philly) +
  geom_sf(aes(fill = LNNBELPOV), color = "transparent") +
  scale_fill_gradientn(colors = c("#FAF9F6", "#c44536"), 
                       name = "LNNBELPOV", 
                       na.value = "transparent") +  # Handle NAs
  theme(legend.text = element_text(size = 9),
        legend.title = element_text(size = 10),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.subtitle = element_text(size = 9, face = "italic"),
        plot.title = element_text(size = 12, face = "bold"),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "grey", fill = NA, size = 0.8)) +
  labs(title = "Logged Transformed Poverty")

map_pctvacant + map_pctsingles + map_pcbachmore + map_lnbelpov100 + 
  plot_layout(ncol = 2)
```

## Regression Results - Emma
*Present the regression output from R. Be sure that your output presents the parameter estimates (and associated standard errors, t-statistics and p-values), as well as the R2, the adjusted R2, and the relevant F-ratio and associated p-value.

*Referencing the regression output in (i) above, interpret the results as in the example included above this report outline.

Four independent variables, the proportion of vacant housing units (PCTVACANT), the proportion of single-family detached homes (PCTSINGLES), the proportion of residents with at least a Bachelor's degree (PCTBACHMOR), and the number of log-transformed households living below the poverty line (LNNBELPOV100), were used to construct ordinary least squares (OLS) regression models to predict the median log-transformed home values (LNMEDHVAL) for the Philadelphia census block group. The results of the regression analysis reveal a link between these block characteristics and house prices.

The residuals from the model show a fairly reasonable distribution of errors, with a minimum residual value of -2.26, a first quartile of -0.20, a median of 0.04, a third quartile of 0.22, and a maximum value of 2.24. This distribution suggests that the model captures changes in housing values reasonably well, although some of the extreme residuals suggest that outliers may exist.

The regression coefficients provide further evidence of the effect of each predictor on LNMEDHVAL. The intercept of the model is 11.11 (p < 0.001), indicating the expected log-transformed median home value when all predictors are held constant at zero. The proportion of vacant housing units (PCTVACANT) had a highly significant negative effect on LNMEDHVAL (Î² = -0.019, p < 0.001), suggesting that the higher the vacancy rate, the lower the median housing value. Specifically, for every 1% increase in vacant housing units, the log-transformed median home value decreases by 0.019 units, highlighting the negative impact of vacancy on property values.

The proportion of single-family detached homes (PCTSINGLES) is significantly and positively correlated with LNMEDHVAL (Î² = 0.003, p < 0.001). This suggests that neighbourhoods with more single-family homes tend to have higher median housing values. Although the effect size is small, it is still statistically significant, suggesting that the presence of single-family homes contributes positively to community home values.

The proportion of residents with at least a bachelor's degree (PCTBACHMOR) has the largest positive effect on LNMEDHVAL (Î² = 0.021, p < 0.001), suggesting that populations with higher levels of educational attainment tend to reside in areas with higher housing values. Each 1 percent increase in the proportion of residents with a bachelor's degree is associated with a 0.021 unit increase in the log-transformed median home value, underscoring the importance of educational attainment as a key factor in housing market dynamics.

In contrast, the number of log-transformed households living below the poverty line (LNNBELPOV100) is negatively correlated with LNMEDHVAL (Î² = -0.079, p < 0.001). This result suggests that higher levels of poverty are associated with lower home values in a neighbourhood group, with each 1 per cent increase in the number of households below the poverty line being associated with a 0.079 unit decrease in the median log-transformed home value.

The model had a multiple R-squared value of 0.6623 and an adjusted R-squared value of 0.6615, indicating that approximately 66% of the variance in LNMEDHVAL is explained by the four predictors. The F-statistic for this model was 840.9 (p < 0.001), further confirming the statistical significance of the model as a whole, and the fact that the predictors collectively explain a significant portion of the variance in housing values for the Philadelphia block group.

The analysis of variance (ANOVA) table provides additional insight into the significance of each predictor in explaining the variation in LNMEDHVAL. The ANOVA decomposes the total variation in LNMEDHVAL into components attributable to each predictor and residual error. For PCTVACANT, the sum of squares is 180.39, with a mean square value of 180.39, and an F-statistic of 1343.09 (p < 0.001). This result confirms that housing vacancy is a significant factor contributing to the variation in housing values. Similarly, PCTSINGLES has a sum of squares of 24.54 and an F-statistic of 182.73 (p < 0.001), confirming the significant, though smaller, positive effect of single-family homes on housing values.

The PCTBACHMOR variable is the strongest predictor, with a sum of squares of 235.12 and an F-statistic of 1750.55 (p < 0.001). This reinforces the importance of educational attainment in driving housing values. Lastly, LNNBELPOV100 has a sum of squares of 11.69 and an F-statistic of 87.05 (p < 0.001), showing that poverty levels, while statistically significant, have a more modest effect compared to other predictors.

The residual sum of squares, which represents the unexplained variation in the model, was 230.34, with a mean square error of 0.134.Overall, the ANOVA results, combined with the OLS regression results, confirmed that all four predictors-PCTVACANT, PCTSINGLES, PCTBACHMOR, and LNNBELPOV100-contribute significantly to explaining the changes in LNMEDHVAL were all significant contributors. These findings provide strong evidence of the robustness of the model and the relevance of neighbourhood characteristics in predicting housing values.

```{r linear regression, message=FALSE, warning=FALSE}

fit <- lm(LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV100, data=reg_data)
summary(fit)
```
```{r anova table, message=FALSE, warning=FALSE}

anova_table <- anova(fit)
anova_table

```


## Regression Assumption Check - Emma

*First state that in this section, you will be talking about testing model assumptions. State that you have already looked at the variable distributions earlier.

*Present scatter plots of the dependent variable and each of the predictors.  State whether each of the relationships seems to be linear, as assumed by the regression model. [Hint: they will not look linear.]

The scatter plot for PCTVACANT shows a general negative relationship between the proportion of vacant housing units and LNMEDHVAL. In the graph, there are clusters of block groups where high vacancy rates correspond to lower housing values, particularly on the left side of the plot where the values of LNMEDHVAL are higher. However, the plot is not perfectly linear. Instead, it reveals a more complex relationship with significant variation in housing values across different vacancy rates. In the middle and lower ranges of vacancy rates, the decline in housing values becomes less pronounced. This suggests that while vacant housing is associated with lower property values, the impact diminishes or becomes less predictable as the vacancy rate changes.

In the scatter plot for PCTSINGLES, a weakly positive trend is observed, though the points are scattered widely around the line, indicating a weak linear relationship. As the percentage of single-family homes increases, the values of LNMEDHVAL tend to increase, but this pattern is not consistent across all block groups. The scatter of points shows significant variability in housing values at various levels of single-family housing, with some block groups exhibiting high values even at lower percentages of single-family homes. This variability suggests that while there is a positive association between single-family housing and higher values, the relationship is more nuanced, and other factors may be influencing house values at the same time.

The scatter plot for PCTBACHMOR, however, shows a much clearer linear relationship. As the proportion of residents with at least a bachelorâ€™s degree increases, the LNMEDHVAL values increase in a more consistent and linear fashion. The points on the graph form a relatively tight band along a positive trend line, indicating that higher education levels within a neighborhood are strongly associated with higher housing values. The consistent upward trend in this graph suggests that educational attainment is a key driver of housing prices, and the linear relationship implies that this variable is well-suited for inclusion in the linear regression model.

The scatter plot for LNNBELPOV100 reveals a predominantly negative relationship, but like PCTVACANT, the association is not strictly linear. In the graph, as the number of households living below the poverty line increases, the LNMEDHVAL values generally decrease. However, the points are scattered widely, particularly at lower levels of poverty, where housing values vary significantly. This indicates that while poverty levels have a negative impact on housing values, the effect is not uniform across all block groups. There is substantial variation in the housing values even in neighborhoods with similar poverty rates, suggesting that other factors may be at play. The non-linear pattern observed in this graph highlights the complexity of povertyâ€™s influence on the housing market.

In summary, the scatterplot shows that while PCTBACHMOR and LNMEDHVAL exhibit a strong and clear linear relationship, the other predictors - in particular PCTVACANT and LNNBELPOV100 - exhibit more complex non-linear patterns. The scatterplots provide important insights into the relationship between the independent variables and housing values, suggesting that while the model is assumed to be linear, it may not fully capture the underlying dynamics. For variables such as PCTVACANT and LNNBELPOV100, the nonlinearity observed in the plots suggests that more complex nonlinear models may provide a better fit and more accurate predictions.

```{r scatterplot, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}

# scatterplot

reg_data %>%
  pivot_longer(cols = c("PCTBACHMOR", "LNNBELPOV100", "PCTVACANT", "PCTSINGLES"),
               names_to = "Variable",
               values_to = "Value") %>% 
ggplot(aes(x = Value, y = LNMEDHVAL)) +
  geom_point(color = "#283d3b", alpha = 0.7, size = 0.4) +
  geom_smooth(method = "lm", color = "#c44536", se = FALSE) +  # Add a linear regression line
  facet_wrap(~ Variable, scales = "free", labeller = as_labeller(c(
    "PCTBACHMOR" = "% with Bachelorâ€™s Degrees or Higher",
    "LNNBELPOV100" = "Households Living in Poverty",
    "PCTVACANT" = "% of Vacant Houses",
    "PCTSINGLES" = "% of Single House Units"
  )))  +
  theme_light() +   
  theme(plot.subtitle = element_text(size = 9,face = "italic"),
        plot.title = element_text(size = 12, face = "bold"), 
        axis.text.x=element_text(size=6),
        axis.text.y=element_text(size=6), 
        axis.title=element_text(size=8)) +
  labs(title = "Scatter Plots of Dependent Variable vs. Predictors", 
       x = "Predictor Value", 
       y = "Log of Median House Value")

```

*Present the histogram of the standardized residuals. State whether the residuals look normal.

The histogram of standardized residuals provides a detailed view of the distribution of the residuals from the OLS regression model. This graph presents the frequency of residual values along the x-axis, with the residuals centered around zero. The shape of the histogram approximates a bell curve, which is characteristic of a normal distributionâ€”a key assumption for OLS regression.

The majority of the residuals are concentrated between -2 and 2 on the x-axis, with the highest frequency occurring near zero. This concentration suggests that most of the predicted values are close to the observed values, leading to residuals that are small and distributed symmetrically around zero. This is a positive sign, as it indicates that the model does not systematically overpredict or underpredict the dependent variable (LNMEDHVAL).

At the center of the distribution, the residuals form a tall, narrow peak, representing a large number of residuals close to zero. This suggests that the model fits most observations well. As we move further away from the center, the frequency of residuals decreases symmetrically, with fewer residuals having large positive or negative values. This tapering off on both sides of the histogram suggests that extreme residuals are relatively rare, which is typical of a normal distribution.

However, there are some noticeable deviations from perfect normality at the tails of the distribution. On the left side of the graph, there are a few residuals with values smaller than -3, and on the right side, there are a few residuals larger than 3. These residuals represent outliersâ€”cases where the modelâ€™s predictions deviate significantly from the observed values. While these extreme values do not appear to dominate the distribution, they are worth further examination, as they could indicate areas where the modelâ€™s assumptions are being violated or where influential points might be affecting the overall model fit.

In summary, the histogram of standardized residuals indicates that the residuals are approximately normally distributed, which supports the assumption of normality for the regression model. Although there are some outliers present, their overall impact on the normality of the residuals seems minimal. The general shape of the histogram suggests that the OLS regression model fits the data reasonably well, with residuals mostly falling within an acceptable range around zero. 

```{r compute residuals, message=FALSE, warning=FALSE}

fitted_values <- fitted(fit)
residuals_values <- residuals(fit)
standardized_residuals <- rstandard(fit)

reg_data <- reg_data %>%
  mutate(
    Fitted = fitted_values,
    Residuals = residuals_values,
    Standardized_Residuals = standardized_residuals)

```


```{r residual histograms, message=FALSE, warning=FALSE}

ggplot(reg_data, aes(x = Standardized_Residuals)) +
  geom_histogram(bins = 30, fill = "#283d3b", alpha = 0.7) +
  labs(title = "Histogram of Standardized Residuals", 
       x = "Standardized Residuals", 
       y = "Frequency") +
  theme_light() +   
  theme(plot.subtitle = element_text(size = 9,face = "italic"),
        plot.title = element_text(size = 12, face = "bold"), 
        axis.text.x=element_text(size=6),
        axis.text.y=element_text(size=6), 
        axis.title=element_text(size=8))

```


*Present the â€˜Standardized Residual by Predicted Valueâ€™ scatter plot. What conclusions can you draw from that? Does there seem to be heteroscedasticity? Do there seem to be outliers? Anything else? Discuss. 
Mention what standardized residuals are.

The scatter plot of standardized residuals vs fitted values is a valuable diagnostic for testing essential regression assumptions, including homoscedasticity and the presence of outliers. The fitted values that the model predicts are plotted on the x-axis, and the standardized residualsâ€”that is, residuals adjusted by their standard deviationâ€”are shown on the y-axis. Because standardized residuals give an indication of the standard deviation of each residual's divergence from the expected value, they make it simple to identify outliers and significant data points. Relatives are generally regarded as normal when they fall between -2 and +2, and anything outside of these bounds can lead to anomalous points that could have an impact on the model's performance.

Homoscedasticity, or the need that residuals show constant variance across all levels of fitted values, is one of the fundamental presumptions of regression. The residuals in this scatter plot show no discernible trend of rising or falling variance with increasing fitted values; instead, they seem to be pretty uniformly distributed around the horizontal line at zero. The fact that there is no obvious funnel shape or systematic variation trend to suggest otherwise suggests that the assumption of homoscedasticity is reasonably satisfied. The notion of constant variance is supported by the residuals' generally constant spread across the fitted value range, which indicates that the variance of errors is still stable.

However, the plot does show some potential outliers, particularly those points that are outside the range of the -3 and +3 standardised residuals. These extreme residuals are located above and below the main residual clusters and may indicate that the model's predicted values deviate significantly from the actual values. Although the number of outliers is relatively small, their presence indicates that the model may not fit all data points well. Outliers such as these may have a disproportionate impact on the model, potentially distorting parameter estimates and exaggerating error terms. Further investigation is needed to determine whether these outliers are due to data entry errors, represent unique situations, or highlight deficiencies in the model specification.

The symmetry of the residuals around the zero line is another positive aspect of the plot. This symmetry means that the model does not systematically over- or under-predict the dependent variable over the range of fitted values (LNMEDHVAL). The symmetrical distribution of the residuals is consistent with a key assumption of ordinary least squares regression, which is that the residuals should have a mean of zero. The lack of significant bias in either direction suggests that the model is generally appropriate.

In addition, although the residuals are generally well clustered around zero, some slight dispersion occurs as the fitted values increase, suggesting that the accuracy of the model predictions may decrease slightly at higher values of LNMEDHVAL. The higher the fitted value, the greater the residual variance, which may indicate the presence of slight heteroskedasticity, but not of sufficient severity to raise significant concerns about the validity of the model. However, this pattern could be explored further to ensure that the model performs well over the entire range of predicted values.

Thus, scatter plots of standardised residuals versus fitted values indicate that the model generally satisfies the assumption of homoskedasticity and that the residuals show a consistent distribution among the fitted values. However, the presence of a few outliers and slight dispersion of higher values warrants further investigation. These diagnostic results suggest that the model fits the data reasonably well, but dealing with outliers and checking for leverage points could improve the robustness and predictive accuracy of the model.


```{r residual plot,  message=FALSE, warning=FALSE}

ggplot(reg_data, aes(x = Fitted, y = Standardized_Residuals)) +
  geom_point(color = "#283d3b", alpha = 0.6) +    # Scatter plot points
  geom_hline(yintercept = 0, linetype = "dashed", color = "#c44536") +   # Add a horizontal line at y = 0
  labs(
    title = "Scatter Plot of Standardized Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Standardized Residuals"
  ) +
  theme_light() +   
  theme(plot.subtitle = element_text(size = 9,face = "italic"),
        plot.title = element_text(size = 12, face = "bold"), 
        axis.text.x=element_text(size=6),
        axis.text.y=element_text(size=6), 
        axis.title=element_text(size=8))


```

*Referencing the maps of the dependent variable and the predictors that you presented earlier, state whether there seems to be spatial autocorrelation in your variables. That is, does it seem that the observations (i.e., block groups) are independent of each other? Briefly discuss.

In the map of LNMEDHVAL (log-transformed median house values), there appears to be a spatial pattern, with higher values concentrated in certain areas, such as Center City and other affluent neighborhoods, and lower values clustered in more economically distressed areas. This suggests that the housing market is not spatially random and that nearby block groups tend to have similar house values, indicative of positive spatial autocorrelation.

Similarly, the map of PCTVACANT (proportion of vacant housing units) shows clear geographic clusters, with higher vacancy rates concentrated in certain parts of the city, particularly in areas experiencing economic decline. This clustering pattern suggests that vacancy rates are spatially correlated, meaning that the vacancy rate in one block group is likely influenced by the rates in adjacent block groups.

For PCTSINGLES (Proportion of single-family homes), the maps also reveal spatial patterns, with block groups characterised by a high proportion of single-family homes, often located in residential areas on the outskirts of a suburb or city. This spatial clustering implies that block groups with similar housing characteristics tend to be in close proximity to each other, suggesting potential spatial autocorrelation.

The PCTBACHMOR (Proportion of Residents with at least a Bachelor's Degree) maps also show a strong spatial pattern, with higher levels of educational attainment concentrated in the more affluent central areas of the city, while lower levels of educational attainment are concentrated in the peripheral areas, which have fewer economic resources. This suggests that educational attainment is spatially correlated, with similar levels of education concentrated in geographically similar neighbourhood groups.

The LNNBELPOV100 (log-transformed number of households living below the poverty line) map shows that in some parts of the city, particularly in economically distressed neighbourhoods, there is a clear concentration of households with higher poverty rates. This spatial concentration of poverty is indicative of positive spatial autocorrelation, whereby groups of neighbourhoods with higher poverty rates tend to be in close proximity to each other.

In summary, the maps of both the dependent variable and the predictors indicate the presence of spatial autocorrelation, with distinct geographic patterns and clusters visible throughout the city. This suggests that observations (block groups) are not independent of each other, as values from nearby block groups are likely to influence each other. The presence of spatial autocorrelation highlights the importance of considering spatial relationships in the analysis, as failure to account for such dependencies may violate regression assumptions and lead to biased or inefficient estimates. The use of spatial regression techniques to better account for these spatial dependencies could be of great benefit to future analyses.

*Now, present the choropleth map of the standardized regression residuals. Do there seem to be any noticeable spatial patterns in them? That is, do they seem to be spatially autocorrelated? You will examine the spatial autocorrelation of the variables and residuals and run spatial regressions in the next assignment. 

The choropleth map of standardized regression residuals provides a detailed geographic breakdown of how well the OLS regression model fits the data across different areas of the city. The map uses a color gradient to represent the magnitude of the residuals, with darker red shades indicating large positive residuals (where the model underestimates the actual values), and lighter shades (toward white) indicating large negative residuals (where the model overestimates the actual values). The standardized residuals range from -6 to +6, offering insight into areas where the model's predictions diverge most from the observed values.

From a spatial perspective, there are several noteworthy patterns in the map. In the northwestern part of the city, particularly along some of the more suburban and affluent areas, dark red shading indicates large positive residuals. This suggests that the model underestimates housing values in these neighborhoods, as the predicted values are consistently lower than the actual observed values. These areas are often characterized by higher-income households and larger single-family homes, suggesting that the model may not fully capture the higher market value trends in these regions, possibly due to unaccounted factors like proximity to high-demand amenities or specific neighborhood features that influence property values.

In contrast, in sections of South and Southwest Philadelphia, as well as parts of North Philadelphia, lighter shaded areas indicate large negative residuals. Here, the model tends to overestimate housing values, meaning that the predicted values are higher than the actual observed values. These neighborhoods may be facing economic challenges, such as higher vacancy rates, lower household incomes, or poverty, which the model has difficulty fully capturing through the selected predictors. The residuals in these areas suggest that housing markets in these neighborhoods are more complex and influenced by localized factors not fully represented in the regression model, such as higher levels of economic distress or neighborhood disinvestment.

Additionally, some central neighborhoods near Center City display more neutral residuals, where the model's predictions are relatively accurate, with values closer to zero. These areas appear in lighter red or pink shades, indicating that the model is performing reasonably well in these parts of the city. This may be because the central areas are more homogeneous in terms of housing values and more likely to align with the trends captured by the model's predictors, such as education levels and vacancy rates.

The overall pattern observed in the map suggests spatial clustering, as block groups with similar residual values tend to be geographically close to each other. For instance, in the northwest, large positive residuals form a contiguous cluster, while large negative residuals are clustered in certain distressed areas of the city. This clustering effect points to the presence of spatial autocorrelation in the residuals, meaning that the model's errors are not randomly distributed, but instead show clear geographic trends.

In other words, therefore, the longitudinal plots of standardised residuals reveal significant spatial patterns, suggesting that the regression model performs differently across communities. The model tends to underestimate housing values in more affluent suburbs and overestimate housing values in economically distressed communities. The spatial pattern of these residuals suggests that there are other geographic or spatial factors that influence housing values that are not fully accounted for in the model. This highlights the need for further spatial analyses, such as incorporating spatial regression models, to account for these dependencies and improve the accuracy of the models. By addressing spatial autocorrelation, future models could provide more accurate forecasts and better insight into the spatial dynamics of housing markets across the city.

```{r residual maps, message=FALSE, warning=FALSE}

philly %>%
  left_join(reg_data %>% dplyr::select(c(POLY_ID, Standardized_Residuals)), by = "POLY_ID") %>% 
  ggplot(.) +
  geom_sf(aes(fill = Standardized_Residuals), color = "transparent") +  # Use geom_sf to map the polygons
  scale_fill_gradientn(colors = c("#FAF9F6", "#c44536"), 
                       name = "Std Residuals", 
                       na.value = "transparent") +  # Choose a color palette, invert direction if needed
  labs(title = "Choropleth Map of Standardized Residuals") +
  theme(legend.text = element_text(size = 9),
        legend.title = element_text(size = 10),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.subtitle = element_text(size = 9, face = "italic"),
        plot.title = element_text(size = 12, face = "bold"),
        panel.background = element_blank(),
        panel.border = element_rect(colour = "grey", fill = NA, size = 0.8))



```

## Additional Analyses - Ziyi


Present the results of the stepwise regression and state whether all 4 predictors in the original model are kept in the final model.

```{r stepwise regression, message=FALSE, warning=FALSE}

stepwise_model <-  stepAIC(fit, direction = "both")
stepwise_model$anova

```

Present the cross-validation results â€“ that is, compare the RMSE of the original model that includes all 4 predictors with the RMSE of the model that only includes PCTVACANT and MEDHHINC as predictors.

```{r cross validation, message=FALSE, warning = FALSE}

lm <-  trainControl(method = "cv", number = 5)

cvlm_model <- train(LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV100, data=reg_data, method = "lm", trControl = lm)

print(cvlm_model)

```

```{r reduce cv model,message=FALSE, warning=FALSE}

cvlm_model_reduced = train(LNMEDHVAL ~ PCTVACANT + MEDHHINC, data = reg_data, method = "lm", trControl = lm)

print(cvlm_model_reduced)
```

# Discussion and Limitations - Emily

a)	Recap what you did in the paper and your findings. Discuss what conclusions you can draw, which variables were significant and whether that was surprising or not.


b)	Talk about the quality of the model â€“ that is, state if this is a good model overall (e.g., R2, F-ratio test), and what other predictors that we didnâ€™t include in our model might be associated with our dependent variable.
Looking at the stepwise regression results, did the final model include all 4 predictors or were some dropped? What does that tell you about the quality of the model? 
Looking at the cross-validation results, was the RMSE better for the 4 predictor model or the 2 predictor model?  


c)	If you havenâ€™t done that in the Results section, talk explicitly about the limitations of the model â€“ that is, mention which assumptions were violated, and if applicable, how that may affect the model/parameter estimation/estimated significance. 
In addition, talk about the limitations of using the NBELPOV100 variable as a predictor â€“ that is, what are some limitations of using the raw number of households living in poverty rather than a percentage?


d)	Would it make sense to run Ridge or LASSO regression here? Explain briefly (~4-5 sentences) what these methods are, when theyâ€™re used, and why they would or would not be appropriate here.









